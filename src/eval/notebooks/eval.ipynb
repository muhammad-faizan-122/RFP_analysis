{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eda8d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = {\n",
    "  \"user_query\": \"what kind of inspection required for this project?\",\n",
    "  \"answer\": \"Special inspections are required for this project. Specifically:\\n*   Where fabrication of a structural assembly is being performed on the premises of a fabricator's shop.\\n*   Prior to the placement of fill, the special inspector shall determine that the site has been prepared in accordance with the contract documents.\",\n",
    "  \"reasoning\": \"Document-1\\nRelevance: Yes\\nReasoning: The document specifies several types of inspections required, such as \\\"special inspections\\\" for structural assembly fabrication, \\\"Grade and mill test reports\\\" for steel elements, and site preparation inspection by a \\\"special inspector.\\\"\\n\\nDocument-2\\nRelevance: No\\nReasoning: The document discusses the reporting, maintenance, and content requirements for inspection reports, but it does not specify what kind of inspections are required for the project.\\n\\nDocument-3\\nRelevance: No\\nReasoning: The document focuses on the documentation and reporting procedures for inspections, including discrepancies and corrections, but it does not specify what kind of inspections are required.\",\n",
    "  \"extracted_requirements\": [\n",
    "    {\n",
    "      \"id\": None,\n",
    "      \"metadata\": {\n",
    "        \"project\": \"Controlled Testing & Inspections for District Wide Additions & Alterations\",\n",
    "        \"company\": \"Edgemont Union Free School District\",\n",
    "        \"file_name\": \"rfp3\"\n",
    "      },\n",
    "      \"page_content\": \"e.​ Where fabrication of a structural assembly is being performed on the premises of a\\nfabricators shop, special inspections shall be required.​\\nf.​ Grade and mill test reports are required for main stress carrying steel elements​\\ng.​ Prior to the placement of fill, the special inspector shall determine that the site has\\nbeen prepared in accordance with the contract documents.​\",\n",
    "      \"type\": \"Document\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": None,\n",
    "      \"metadata\": {\n",
    "        \"company\": \"Edgemont Union Free School District\",\n",
    "        \"project\": \"Controlled Testing & Inspections for District Wide Additions & Alterations\",\n",
    "        \"file_name\": \"rfp3\"\n",
    "      },\n",
    "      \"page_content\": \"b.​ Copies of all special inspection reports shall be provided to the Architect and\\nOwner’s Representative/Construction Manager on a weekly basis. Any inspection/\\nreport that indicates a failure or a deviation from the contract documents shall be\\nprovided to the Architect and Owner’s representative immediately within (24\\nhours of the inspection).​\\nc.​ The testing agency shall be required to maintain a special inspection book. The\\nbook shall be a three-ring binder which contains copies of all inspection reports.\\nAt the completion of the project three (3) complete copies of the inspection report\\nbook shall be turned over to the Owner.​\\nd.​ All inspection reports shall include the date of the inspection, the specific location\\nwhere the inspection was conducted and that the work inspected was done in\\nconformance with the construction documents or shall be corrected, along with all\\nother pertinent information.​\",\n",
    "      \"type\": \"Document\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": None,\n",
    "      \"metadata\": {\n",
    "        \"company\": \"Edgemont Union Free School District\",\n",
    "        \"project\": \"Controlled Testing & Inspections for District Wide Additions & Alterations\",\n",
    "        \"file_name\": \"rfp3\"\n",
    "      },\n",
    "      \"page_content\": \"proposal. Proof of qualifications must be submitted to the Owner as part of the proposal.\\nAll inspections must be documented with reports indicating that all work was done in conformance to\\napproved construction documents, and be furnished to the Code Enforcement Official, Owner, its\\ndesignee, and Architect. Any discrepancies must be documented appropriately and reported, as well as\\ncorrections must also be documented and reported to the Code Enforcement Official, Owner, its\\ndesignee, and Architect.\",\n",
    "      \"type\": \"Document\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa799a9",
   "metadata": {},
   "source": [
    "# calculate the retrieved relevancy score \n",
    "use reasoning output from system response, responing was generated using how retrieved are relevant with respect to user query. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d27ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-1\n",
      "Relevance: Yes\n",
      "Reasoning: The document specifies several types of inspections required, such as \"special inspections\" for structural assembly fabrication, \"Grade and mill test reports\" for steel elements, and site preparation inspection by a \"special inspector.\"\n",
      "\n",
      "Document-2\n",
      "Relevance: No\n",
      "Reasoning: The document discusses the reporting, maintenance, and content requirements for inspection reports, but it does not specify what kind of inspections are required for the project.\n",
      "\n",
      "Document-3\n",
      "Relevance: No\n",
      "Reasoning: The document focuses on the documentation and reporting procedures for inspections, including discrepancies and corrections, but it does not specify what kind of inspections are required.\n"
     ]
    }
   ],
   "source": [
    "print(response['reasoning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af36908d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_retrieved_docs = len(response['extracted_requirements'])\n",
    "total_retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fc19292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count relevanance \"yes\" in reasoning text\n",
    "relevant_count = response['reasoning'].lower().count(\"relevance: yes\")\n",
    "relevant_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a67deab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.33333333333333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc_percentage = (relevant_count / total_retrieved_docs) * 100\n",
    "relevant_doc_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a34b8c",
   "metadata": {},
   "source": [
    "# Eval reasoning Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b071f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_reasoning_quality_prompt = \"\"\"You are expert in evaluating the quality of reasoning provided by a system \\\n",
    "in response to a user query and relevant retrieved documents.\n",
    "Given the reasoning text, user query and retrieved documents below, assess its quality based on the following criteria:\n",
    "1. Clarity: Is the reasoning clearly articulated and easy to understand?\n",
    "2. Relevance: Does the reasoning directly address the user query and the context provided?\n",
    "3. Depth: Does the reasoning provide sufficient depth and detail to justify the conclusions drawn?\n",
    "Provide a score from 1 to 10 for each criterion, where 1 is poor and 10 is excellent. Additionally, provide a brief explanation for each score.\n",
    "\n",
    "<user_query>\n",
    "{user_query}\n",
    "</user_query?\n",
    "\n",
    "<retrieved_documents>\n",
    "{retrieved_documents}\n",
    "</retrieved_documents>\n",
    "\n",
    "<reasoning_text>\n",
    "{reasoning_text}\n",
    "</reasoning_text>\n",
    "\n",
    "Please provide your evaluation in the following format:\n",
    "Clarity Score: <score>\n",
    "Clarity Explanation: <explanation>\n",
    "Relevance Score: <score>\n",
    "Relevance Explanation: <explanation>\n",
    "Depth Score: <score>\n",
    "Depth Explanation: <explanation>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f81677b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def format_retrieved_document(retrieved_docs: List[dict]):\n",
    "    relevant_document = \"\"\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        relevant_document += f\"Document-{i+1}:\\n{doc['page_content']}\\n\\n\"\n",
    "    return relevant_document\n",
    "\n",
    "formatted_retrieved_doc = format_retrieved_document(response[\"extracted_requirements\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61609b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f7f46e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Document-1\\nRelevance: Yes\\nReasoning: The document specifies several types of inspections required, such as \"special inspections\" for structural assembly fabrication, \"Grade and mill test reports\" for steel elements, and site preparation inspection by a \"special inspector.\"\\n\\nDocument-2\\nRelevance: No\\nReasoning: The document discusses the reporting, maintenance, and content requirements for inspection reports, but it does not specify what kind of inspections are required for the project.\\n\\nDocument-3\\nRelevance: No\\nReasoning: The document focuses on the documentation and reporting procedures for inspections, including discrepancies and corrections, but it does not specify what kind of inspections are required.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"reasoning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91e48eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "# System message\n",
    "message = eval_reasoning_quality_prompt.format(\n",
    "    user_query=response['user_query'], \n",
    "    reasoning_text=response[\"reasoning\"],\n",
    "    retrieved_documents=format_retrieved_document(response[\"extracted_requirements\"])\n",
    "    ) \n",
    "\n",
    "# Generate question \n",
    "resoning_eval_response = llm.invoke([\n",
    "        HumanMessage(content=message)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c3f76373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clarity Score: 9\n",
      "Clarity Explanation: The reasoning is very clear and easy to understand. Each document's relevance is explicitly stated (\"Yes\" or \"No\"), followed by a concise and direct explanation that justifies the assessment.\n",
      "\n",
      "Relevance Score: 10\n",
      "Relevance Explanation: The reasoning directly addresses the user query \"what kind of inspection required for this project?\". For Document-1, it accurately extracts and lists the specific types of inspections mentioned. For Documents 2 and 3, it correctly identifies that they discuss reporting and documentation procedures rather than the *kind* of inspections, thus appropriately deeming them irrelevant to the specific query.\n",
      "\n",
      "Depth Score: 9\n",
      "Depth Explanation: The reasoning provides sufficient depth. For Document-1, it lists the specific types of inspections, which is adequate detail to answer the query. For Documents 2 and 3, it explains *why* they are not relevant by summarizing their content (reporting, documentation, etc.), which provides enough justification for the \"No\" relevance assessment without being overly verbose.\n"
     ]
    }
   ],
   "source": [
    "print(resoning_eval_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd276e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count relevanance \"yes\" in reasoning text\n",
    "relevant_count = response['reasoning'].lower().count(\"Clarity Score: yes\")\n",
    "relevant_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "628014f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"clarity\": {\n",
      "    \"score\": 9,\n",
      "    \"explanation\": \"The reasoning is very clear and easy to understand. Each document's relevance is explicitly stated (\\\"Relevance: Yes/No\\\") followed by a concise explanation.\"\n",
      "  },\n",
      "  \"relevance\": {\n",
      "    \"score\": 10,\n",
      "    \"explanation\": \"The reasoning directly addresses the user query by identifying which documents specify the *kind* of inspections required and which ones do not, explaining why. The distinction between \\\"kind of inspections\\\" and \\\"reporting/procedures\\\" is accurately made.\"\n",
      "  },\n",
      "  \"depth\": {\n",
      "    \"score\": 9,\n",
      "    \"explanation\": \"The reasoning provides sufficient detail to justify its conclusions. For Document-1, it lists specific examples of inspections. For Documents 2 and 3, it clearly explains what those documents *do* cover and why that doesn't answer the user's specific question about the *kind* of inspections. The level of detail is appropriate for evaluating document relevance.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_scores(text: str):\n",
    "    \"\"\"\n",
    "    Extract Score + Explanation pairs and convert to JSON.\n",
    "    \"\"\"\n",
    "    pattern = r\"\"\"\n",
    "        (?P<name>\\w+)\\s+Score:\\s*(?P<score>\\d+)\\s*\n",
    "        (?P<name2>\\w+)\\s+Explanation:\\s*(?P<explanation>.*?)(?=\\n\\w+\\s+Score:|\\Z)\n",
    "    \"\"\"\n",
    "\n",
    "    matches = re.finditer(pattern, text, re.DOTALL | re.VERBOSE)\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    for m in matches:\n",
    "        name = m.group(\"name\").strip().lower()  # clarity, relevance, depth\n",
    "        score = int(m.group(\"score\"))\n",
    "        explanation = m.group(\"explanation\").strip()\n",
    "\n",
    "        result[name] = {\n",
    "            \"score\": score,\n",
    "            \"explanation\": explanation\n",
    "        }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Example input text\n",
    "text = \"\"\"\n",
    "Clarity Score: 9\n",
    "Clarity Explanation: The reasoning is very clear and easy to understand. Each document's relevance is explicitly stated (\"Relevance: Yes/No\") followed by a concise explanation.\n",
    "\n",
    "Relevance Score: 10\n",
    "Relevance Explanation: The reasoning directly addresses the user query by identifying which documents specify the *kind* of inspections required and which ones do not, explaining why. The distinction between \"kind of inspections\" and \"reporting/procedures\" is accurately made.\n",
    "\n",
    "Depth Score: 9\n",
    "Depth Explanation: The reasoning provides sufficient detail to justify its conclusions. For Document-1, it lists specific examples of inspections. For Documents 2 and 3, it clearly explains what those documents *do* cover and why that doesn't answer the user's specific question about the *kind* of inspections. The level of detail is appropriate for evaluating document relevance.\n",
    "\"\"\"\n",
    "\n",
    "# Extract JSON\n",
    "output = extract_scores(text)\n",
    "\n",
    "# Pretty print JSON\n",
    "print(json.dumps(output, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "75a06ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Score (out of 100): 93.33\n"
     ]
    }
   ],
   "source": [
    "# Extract individual scores\n",
    "clarity = output[\"clarity\"][\"score\"]\n",
    "relevance = output[\"relevance\"][\"score\"]\n",
    "depth = output[\"depth\"][\"score\"]\n",
    "\n",
    "# Calculate combined score out of 100\n",
    "total_score = clarity + relevance + depth\n",
    "combined_score = (total_score / 30) * 100\n",
    "\n",
    "combined_score = round(combined_score, 2)\n",
    "\n",
    "print(\"Combined Score (out of 100):\", combined_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367cab78",
   "metadata": {},
   "source": [
    "# RAG answer eval \n",
    "given rag answer is relevant to user query and retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a34b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_relevancy_prompt = \"\"\"You are expert in evaluating the relevancy of an answer provided by a system \\\n",
    "in response to a user query and relevant retrieved documents.\n",
    "Given the answer, user query and retrieved documents below, assess its relevancy based on the following criteria:\n",
    "1. Accuracy: Does the answer accurately address the user query based on the information from the retrieved documents?\n",
    "2. Completeness: Does the answer provide a complete response, covering all necessary aspects of the user query?\n",
    "3. Clarity: Is the answer clearly articulated and easy to understand?\n",
    "Provide a score from 1 to 10 for each criterion, where 1 is poor and 10 is excellent. Additionally, provide a brief explanation for each score.\n",
    "<user_query>\n",
    "{user_query}\n",
    "</user_query?\n",
    "\n",
    "<relevant_documents>\n",
    "{relevant_documents}\n",
    "</relevant_documents>\n",
    "\n",
    "<answer_text>\n",
    "{answer}\n",
    "</answer_text>\n",
    "\n",
    "Please provide your evaluation in the following format:\n",
    "Accuracy Score: <score>\n",
    "Accuracy Explanation: <explanation>\n",
    "Completeness Score: <score>\n",
    "Completeness Explanation: <explanation>\n",
    "Clarity Score: <score>\n",
    "Clarity Explanation: <explanation>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c219d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "# System message\n",
    "message = answer_relevancy_prompt.format(\n",
    "    user_query=response['user_query'], \n",
    "    relevant_documents=format_retrieved_document(response[\"extracted_requirements\"]),\n",
    "    answer=response[\"answer\"]\n",
    "    ) \n",
    "\n",
    "# Generate question \n",
    "answer_eval_response = llm.invoke([\n",
    "        HumanMessage(content=message)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4450c105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 10\n",
      "Accuracy Explanation: The answer accurately extracts information directly from Document-1 regarding the types of special inspections required. All points mentioned in the answer are verifiable and correct based on the provided documents.\n",
      "\n",
      "Completeness Score: 7\n",
      "Completeness Explanation: The answer covers two specific types of special inspections mentioned in Document-1. However, it misses one additional type of required report/inspection mentioned in Document-1: \"Grade and mill test reports are required for main stress carrying steel elements.\" Including this would make the answer more complete.\n",
      "\n",
      "Clarity Score: 10\n",
      "Clarity Explanation: The answer is very clearly articulated, starting with a general statement and then using bullet points to list the specific requirements. It is easy to read and understand.\n"
     ]
    }
   ],
   "source": [
    "print(answer_eval_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd37a701",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = extract_scores(answer_eval_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f548f981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Score (out of 100): 90.0\n"
     ]
    }
   ],
   "source": [
    "# Extract individual scores\n",
    "clarity = output[\"clarity\"][\"score\"]\n",
    "completeness = output[\"completeness\"][\"score\"]\n",
    "accuracy = output[\"accuracy\"][\"score\"]\n",
    "\n",
    "# Calculate combined score out of 100\n",
    "total_score = clarity + completeness + accuracy\n",
    "combined_score = (total_score / 30) * 100\n",
    "\n",
    "combined_score = round(combined_score, 2)\n",
    "\n",
    "print(\"Combined Score (out of 100):\", combined_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e503f0",
   "metadata": {},
   "source": [
    "# test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a34aa34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da9f878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "654d2f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = {\n",
    "  \"user_query\": \"what kind of inspection required for this project?\",\n",
    "  \"answer\": \"Special inspections are required for this project. Specifically:\\n*   Where fabrication of a structural assembly is being performed on the premises of a fabricator's shop.\\n*   Prior to the placement of fill, the special inspector shall determine that the site has been prepared in accordance with the contract documents.\",\n",
    "  \"reasoning\": \"Document-1\\nRelevance: Yes\\nReasoning: The document specifies several types of inspections required, such as \\\"special inspections\\\" for structural assembly fabrication, \\\"Grade and mill test reports\\\" for steel elements, and site preparation inspection by a \\\"special inspector.\\\"\\n\\nDocument-2\\nRelevance: No\\nReasoning: The document discusses the reporting, maintenance, and content requirements for inspection reports, but it does not specify what kind of inspections are required for the project.\\n\\nDocument-3\\nRelevance: No\\nReasoning: The document focuses on the documentation and reporting procedures for inspections, including discrepancies and corrections, but it does not specify what kind of inspections are required.\",\n",
    "  \"extracted_requirements\": [\n",
    "    {\n",
    "      \"id\": None,\n",
    "      \"metadata\": {\n",
    "        \"project\": \"Controlled Testing & Inspections for District Wide Additions & Alterations\",\n",
    "        \"company\": \"Edgemont Union Free School District\",\n",
    "        \"file_name\": \"rfp3\"\n",
    "      },\n",
    "      \"page_content\": \"e.​ Where fabrication of a structural assembly is being performed on the premises of a\\nfabricators shop, special inspections shall be required.​\\nf.​ Grade and mill test reports are required for main stress carrying steel elements​\\ng.​ Prior to the placement of fill, the special inspector shall determine that the site has\\nbeen prepared in accordance with the contract documents.​\",\n",
    "      \"type\": \"Document\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": None,\n",
    "      \"metadata\": {\n",
    "        \"company\": \"Edgemont Union Free School District\",\n",
    "        \"project\": \"Controlled Testing & Inspections for District Wide Additions & Alterations\",\n",
    "        \"file_name\": \"rfp3\"\n",
    "      },\n",
    "      \"page_content\": \"b.​ Copies of all special inspection reports shall be provided to the Architect and\\nOwner’s Representative/Construction Manager on a weekly basis. Any inspection/\\nreport that indicates a failure or a deviation from the contract documents shall be\\nprovided to the Architect and Owner’s representative immediately within (24\\nhours of the inspection).​\\nc.​ The testing agency shall be required to maintain a special inspection book. The\\nbook shall be a three-ring binder which contains copies of all inspection reports.\\nAt the completion of the project three (3) complete copies of the inspection report\\nbook shall be turned over to the Owner.​\\nd.​ All inspection reports shall include the date of the inspection, the specific location\\nwhere the inspection was conducted and that the work inspected was done in\\nconformance with the construction documents or shall be corrected, along with all\\nother pertinent information.​\",\n",
    "      \"type\": \"Document\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": None,\n",
    "      \"metadata\": {\n",
    "        \"company\": \"Edgemont Union Free School District\",\n",
    "        \"project\": \"Controlled Testing & Inspections for District Wide Additions & Alterations\",\n",
    "        \"file_name\": \"rfp3\"\n",
    "      },\n",
    "      \"page_content\": \"proposal. Proof of qualifications must be submitted to the Owner as part of the proposal.\\nAll inspections must be documented with reports indicating that all work was done in conformance to\\napproved construction documents, and be furnished to the Code Enforcement Official, Owner, its\\ndesignee, and Architect. Any discrepancies must be documented appropriately and reported, as well as\\ncorrections must also be documented and reported to the Code Enforcement Official, Owner, its\\ndesignee, and Architect.\",\n",
    "      \"type\": \"Document\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e9ba1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_relevancy_score': 33.33,\n",
       " 'reasoning_quality_score': 93.33,\n",
       " 'retrieved_relevancy_score': 33.33333333333333}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.eval.eval_rag import evaluate_rag_response\n",
    "\n",
    "\n",
    "evaluate_rag_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd41542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6440f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477313ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langsmith-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
